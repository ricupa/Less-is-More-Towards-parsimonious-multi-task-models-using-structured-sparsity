
##### conda activate MTLenv
### python main.py --config_exp config/exp_single_mtl_NYU.yaml

# 1. segmentsemantic
# 2. depth_euclidean
# 3. surface_normal
# 4. edge_texture
## 5. multi_seg_depth
## 6. multi_seg_sn
## 7. multi_sn_depth
## 8. multi_seg_sn_depth

'Experiment_name': '8_multi_seg_sn_depth_lambda1e-6' 
'dataset_name' : 'NYU'  ###### 'NYU'
'task_list': ['segmentsemantic','surface_normal','depth_euclidean']  ###
### 'surface_normal', 'edge_texture', 'segmentsemantic','depth_euclidean'
'setup': 'multitask' #### 'multitask', 'singletask'
'group_sparsity' : True
'sparsity_threshold': 0 #### if sparsity needs to be introduced after some epochs, 0 means it was applied from the start.
'backbone' : 'resnetd50' #### resnetd50,resnetd101
'checkpoint': False 
'checkpoint_folder': '../results/runs/'
'num_trials': 0
'wandb_img_log': False



# COMBINE LOSSES
'comb_loss' : 'uncertainity'   # 'uncertainity', 'sum', 'wt_sum'

# BATCH SPECS
'train_batch_size' : 16   
'val_batch_size' : 8
'test_batch_size' : 8

# HYPERPARAMETERS

'input_shape': 256
'epochs' : 1000
'num_workers': 8
'earlystop_patience': 25              
'task_earlystop_patience' : 25        
'input_img_channels': 3


# LOSS FUNCTION
### seg loss function (for example)
'seg_loss_fn': 'softCEloss'   ####  dice, Tversky,  softCEloss, Focal


#  NON SPARSE OPTIMIZER PARAMETERS (for the task heads)
'optimizer': 'adam'    ### 'sgd', 'adamw' , 'adam' 
'optimizer_params': 
    'learning_rate': 0.0001
    'betas': [0.9, 0.999]
    'weight_decay' : 0.01
    'penalty' : 'l1_l2'
    'lambda' : 0.00001   #### not being used 

# BACKBONE OPTIMIZER PARAMETERS
'bb_optimizer': 'adam'    ### 'sgd', 'adamw' , 'adam'  #### in case of sparsity it is always ADAMW
'bb_optimizer_params': 
    'learning_rate': 0.0001 #####0.00001
    'betas': [0.9, 0.999]
    'weight_decay' : 0.1
    'penalty' : 'l1_l2'
    'lambda' : 0.000001 #### for sparsity 
    
#### DATA 
'num_input_ch' : 3
'data_dir_NYU' : "../data/NYUD_MT"

